{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib qt\n",
    "#%matplotlib notebook\n",
    "#%matplotlib inline\n",
    "import os\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '-1' #Comment to Enable GPU\n",
    "import numpy as np\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "from numpy.random import seed\n",
    "seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(2)\n",
    "\n",
    "from numpy import array\n",
    "from random import randint\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import scipy.io as sio\n",
    "from numpy import genfromtxt\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras import initializers\n",
    "from keras import layers\n",
    "from keras.layers import *\n",
    "from keras.utils import *\n",
    "from keras.models import *\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras__trained_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Load matlab 3 dimensional array into Jupiter notebook ####\n",
    "\n",
    "mat_contents = sio.loadmat('hyperspectral_images/S0_trimmed.mat') #loads .mat file\n",
    "sand_0=mat_contents['S0_trimmed'] #extracts data from .mat file\n",
    "print ('0% water image shape', sand_0.shape)\n",
    "\n",
    "mat_contents = sio.loadmat('hyperspectral_images/S5_trimmed.mat') #loads .mat file\n",
    "sand_5=mat_contents['S5_trimmed'] #extracts data from .mat file\n",
    "print ('5% water image shape', sand_5.shape)\n",
    "\n",
    "mat_contents = sio.loadmat('hyperspectral_images/S10_trimmed.mat') #loads .mat file\n",
    "sand_10=mat_contents['S10_trimmed'] #extracts data from .mat file\n",
    "print ('10% water image shape', sand_10.shape)\n",
    "\n",
    "mat_contents = sio.loadmat('hyperspectral_images/S15_trimmed.mat') #loads .mat file\n",
    "sand_15=mat_contents['S15_trimmed'] #extracts data from .mat file\n",
    "print ('15% water image shape', sand_15.shape)\n",
    "\n",
    "mat_contents = sio.loadmat('hyperspectral_images/C0_trimmed.mat') #loads .mat file\n",
    "clay_0=mat_contents['C0_trimmed'] #extracts data from .mat file\n",
    "print ('0% water image shape', clay_0.shape)\n",
    "\n",
    "mat_contents = sio.loadmat('hyperspectral_images/C5_trimmed.mat') #loads .mat file\n",
    "clay_5=mat_contents['C5_trimmed'] #extracts data from .mat file\n",
    "print ('5% water image shape', clay_5.shape)\n",
    "\n",
    "mat_contents = sio.loadmat('hyperspectral_images/C10_trimmed.mat') #loads .mat file\n",
    "clay_10=mat_contents['C10_trimmed'] #extracts data from .mat file\n",
    "print ('10% water image shape', clay_10.shape)\n",
    "\n",
    "mat_contents = sio.loadmat('hyperspectral_images/C15_trimmed.mat') #loads .mat file\n",
    "clay_15=mat_contents['C15_trimmed'] #extracts data from .mat file\n",
    "print ('15% water image shape', clay_15.shape)\n",
    "\n",
    "mat_contents = sio.loadmat('hyperspectral_images/C20_trimmed.mat') #loads .mat file\n",
    "clay_20=mat_contents['C20_trimmed'] #extracts data from .mat file\n",
    "print ('20% water image shape', clay_20.shape)\n",
    "\n",
    "mat_contents = sio.loadmat('hyperspectral_images/SC0_trimmed.mat') #loads .mat file\n",
    "sand_clay_0=mat_contents['SC0_trimmed'] #extracts data from .mat file\n",
    "print ('0% water image shape', sand_clay_0.shape)\n",
    "\n",
    "mat_contents = sio.loadmat('hyperspectral_images/SC5_trimmed.mat') #loads .mat file\n",
    "sand_clay_5=mat_contents['SC5_trimmed'] #extracts data from .mat file\n",
    "print ('5% water image shape', sand_clay_5.shape)\n",
    "\n",
    "mat_contents = sio.loadmat('hyperspectral_images/SC10_trimmed.mat') #loads .mat file\n",
    "sand_clay_10=mat_contents['SC10_trimmed'] #extracts data from .mat file\n",
    "print ('10% water image shape', sand_clay_10.shape)\n",
    "\n",
    "mat_contents = sio.loadmat('hyperspectral_images/SC15_trimmed.mat') #loads .mat file\n",
    "sand_clay_15=mat_contents['SC15_trimmed'] #extracts data from .mat file\n",
    "print ('15% water image shape', sand_clay_15.shape)\n",
    "\n",
    "mat_contents = sio.loadmat('hyperspectral_images/SC20_trimmed.mat') #loads .mat file\n",
    "sand_clay_20=mat_contents['SC20_trimmed'] #extracts data from .mat file\n",
    "print ('20% water image shape', sand_clay_20.shape)\n",
    "\n",
    "mat_contents = sio.loadmat('hyperspectral_images/SC25_trimmed.mat') #loads .mat file\n",
    "sand_clay_25=mat_contents['SC25_trimmed'] #extracts data from .mat file\n",
    "print ('25% water image shape', sand_clay_25.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### To check data validity visually ####\n",
    "from spectral import *\n",
    "view = imshow(sand_0)\n",
    "title_obj = plt.title('0% water in sand')\n",
    "\n",
    "view = imshow(sand_5)\n",
    "title_obj = plt.title('5% water in sand')\n",
    "\n",
    "view = imshow(sand_10)\n",
    "title_obj = plt.title('10% water in sand')\n",
    "\n",
    "view = imshow(sand_15)\n",
    "title_obj = plt.title('15% water in sand')\n",
    "\n",
    "view = imshow(clay_0)\n",
    "title_obj = plt.title('0% water in clay')\n",
    "\n",
    "view = imshow(clay_5)\n",
    "title_obj = plt.title('5% water in clay')\n",
    "\n",
    "view = imshow(clay_10)\n",
    "title_obj = plt.title('10% water in clay')\n",
    "\n",
    "view = imshow(clay_15)\n",
    "title_obj = plt.title('15% water in clay')\n",
    "\n",
    "view = imshow(clay_20)\n",
    "title_obj = plt.title('20% water in clay')\n",
    "\n",
    "view = imshow(sand_clay_0)\n",
    "title_obj = plt.title('0% water in sand-clay')\n",
    "\n",
    "view = imshow(sand_clay_5)\n",
    "title_obj = plt.title('5% water in sand-clay')\n",
    "\n",
    "view = imshow(sand_clay_10)\n",
    "title_obj = plt.title('10% water in sand-clay')\n",
    "\n",
    "view = imshow(sand_clay_15)\n",
    "title_obj = plt.title('15% water in sand-clay')\n",
    "\n",
    "view = imshow(sand_clay_20)\n",
    "title_obj = plt.title('20% water in sand-clay')\n",
    "\n",
    "view = imshow(sand_clay_25)\n",
    "title_obj = plt.title('25% water in sand-clay')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### To check data validity visually ####\n",
    "from spectral import *\n",
    "view = imshow(image_data5)\n",
    "title_obj = plt.title('5% water image')\n",
    "\n",
    "#view = imshow(image_data10)\n",
    "#title_obj = plt.title('10% water image')\n",
    "## Filter for saturated pixels\n",
    "for i in range(0, 256):\n",
    "    for j in range(0, 256):\n",
    "        for k in range(0, 288):\n",
    "            if image_data10[j, i, k] > 100: # Threhold value for saturated pixel from 0 to 1000\n",
    "                for k in range(0, 288):\n",
    "                    image_data10[j, i, k] = image_data10[j, i-1, k]\n",
    "                break\n",
    "        continue                   \n",
    "view = imshow(image_data10)\n",
    "title_obj = plt.title('10% water image (filtered)')\n",
    "view = imshow(image_data15)\n",
    "title_obj = plt.title('15% water image')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Save reflectance graph for each pixel ####\n",
    "k=1\n",
    "for i in range(0, 5):\n",
    "    for j in range(0, 5):\n",
    "        pic = image_data10[i, j, :]\n",
    "        count = j+k\n",
    "        plt.figure(count)\n",
    "        plt.plot(pic)\n",
    "        plt.savefig(\"training_pics/%s.png\" % count)\n",
    "        plt.close(count)\n",
    "    k = k+5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Segmentation of picture into multiple pictures and arrangment into cifar10 dataset style ####\n",
    "image_data_segments = list()\n",
    "image_data_segments_test = list()\n",
    "n=8 #defines number of segmentation per side (only even number)\n",
    "p=32 #defines target segmented picture size\n",
    "k=0 #counter for picture height segmentation\n",
    "\n",
    "for i in range(0, n):\n",
    "    for j in range(0, n):\n",
    "        #Segments picture row by row\n",
    "        if j<n-1:\n",
    "            image_data_segment5 = image_data5[p*k:p*(k+1),p*j:p*(j+1),:]\n",
    "            image_data_segments.append(image_data_segment5)\n",
    "        else:\n",
    "            image_data_segment5 = image_data5[p*k:p*(k+1),p*j:p*(j+1),:]\n",
    "            image_data_segments_test.append(image_data_segment5)\n",
    "    for j in range(0, n):\n",
    "        if j<n-1:\n",
    "            image_data_segment10 = image_data10[p*k:p*(k+1),p*j:p*(j+1),:]\n",
    "            image_data_segments.append(image_data_segment10)\n",
    "        else:\n",
    "            image_data_segment10 = image_data10[p*k:p*(k+1),p*j:p*(j+1),:]\n",
    "            image_data_segments_test.append(image_data_segment10)\n",
    "    for j in range(0, n):\n",
    "        if j<n-1:\n",
    "            image_data_segment15 = image_data15[p*k:p*(k+1),p*j:p*(j+1),:]\n",
    "            image_data_segments.append(image_data_segment15)\n",
    "        else:\n",
    "            image_data_segment15 = image_data15[p*k:p*(k+1),p*j:p*(j+1),:]\n",
    "            image_data_segments_test.append(image_data_segment15)\n",
    "    k += 1\n",
    "    \n",
    "\n",
    "x_train = array(image_data_segments)\n",
    "x_test = array(image_data_segments_test)\n",
    "print ('x_train shape:', x_train.shape)\n",
    "print ('x_test shape:', x_test.shape)\n",
    "\n",
    "##  Create cifar10 style labels array \n",
    "y_labels = list()\n",
    "y_labels_test = list()\n",
    "label = np.array([0, 1, 2]) #sets label class value\n",
    "\n",
    "for i in range(0, ((n*n)*3)//3):\n",
    "    if i<(n-1)*n:\n",
    "        y_label=label[0]\n",
    "        y_labels.append(y_label)\n",
    "    else:\n",
    "        y_label=label[0]\n",
    "        y_labels_test.append(y_label) \n",
    "for i in range(0, ((n*n)*3)//3):\n",
    "    if i<(n-1)*n:\n",
    "        y_label=label[1]\n",
    "        y_labels.append(y_label)\n",
    "    else:\n",
    "        y_label=label[1]\n",
    "        y_labels_test.append(y_label)    \n",
    "for i in range(0, ((n*n)*3)//3):\n",
    "    if i<(n-1)*n:\n",
    "        y_label=label[2]\n",
    "        y_labels.append(y_label)\n",
    "    else:\n",
    "        y_label=label[2]\n",
    "        y_labels_test.append(y_label) \n",
    "    \n",
    "y_train = array(y_labels)\n",
    "y_train = y_train.reshape(len(x_train), 1)\n",
    "y_test = array(y_labels_test)\n",
    "y_test = y_test.reshape(len(x_test), 1)\n",
    "\n",
    "print ('y_train shape:', y_train.shape)\n",
    "print ('y_test shape:', y_test.shape)\n",
    "#print ('Labels array:', y_train)\n",
    "\n",
    "## hyperparameters section \n",
    "batch_size = 64\n",
    "num_classes = 3\n",
    "epochs = 200\n",
    "\n",
    "## Convert class vectors to binary class matrices.\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "#print (y_train)\n",
    "#print (y_test)\n",
    "np.asarray(x_train)\n",
    "np.asarray(x_test)\n",
    "np.asarray(y_train)\n",
    "np.asarray(y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tempfile import TemporaryFile\n",
    "training_data = TemporaryFile()\n",
    "np.savez('training_data', x_train, x_test, y_train, y_test)\n",
    "#np.savez_compressed('123', x_train=x_train, x_test=x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### CNN structure (Functional API Model Style) ####\n",
    "\n",
    "## Uncomment initializer to be used \n",
    "#initializer = keras.initializers.Ones()\n",
    "#initializer = keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=True)\n",
    "#initializer = keras.initializers.RandomUniform(minval=-0.05, maxval=0.05, seed=seed)\n",
    "#initializer = keras.initializers.TruncatedNormal(mean=0.0, stddev=0.05, seed=None)\n",
    "#initializer = keras.initializers.VarianceScaling(scale=1.0, mode='fan_in', distribution='normal', seed=None)\n",
    "initializer = keras.initializers.Orthogonal(gain=2, seed=True)\n",
    "#initializer = keras.initializers.lecun_uniform(seed=True)\n",
    "#initializer = keras.initializers.glorot_normal(seed=None)\n",
    "#initializer = keras.initializers.glorot_uniform(seed=None)\n",
    "#initializer = keras.initializers.he_normal(seed=True)\n",
    "#initializer = keras.initializers.lecun_normal(seed=None)\n",
    "#initializer = keras.initializers.he_uniform(seed=None)\n",
    "\n",
    "\n",
    "input1 = Input(shape=(32,32,288))\n",
    "\n",
    "x = Conv2D(64, kernel_size=1, activation='relu', kernel_initializer=initializer)(input1)\n",
    "#x = Conv2D(288, kernel_size=7, padding='same' ,activation='relu', kernel_initializer=initializer)(x)\n",
    "#x = AveragePooling2D(pool_size=(2, 2))(x)\n",
    "#x = Dropout(0.2)(x)\n",
    "\n",
    "#x = Conv2D(288, kernel_size=3, padding='same' ,activation='relu', kernel_initializer=initializer)(x)\n",
    "x = Conv2D(32, kernel_size=7, padding='same' ,activation='relu', kernel_initializer=initializer)(x)\n",
    "x = AveragePooling2D(pool_size=(2, 2))(x)\n",
    "#x = Dropout(0.2)(x)\n",
    "\n",
    "x = Conv2D(32, kernel_size=5, padding='same' ,activation='relu', kernel_initializer=initializer)(x)\n",
    "#x = Conv2D(32, kernel_size=7, padding='same' ,activation='relu', kernel_initializer=initializer)(x)\n",
    "x = AveragePooling2D(pool_size=(2, 2))(x)\n",
    "#x = Dropout(0.2)(x)\n",
    "\n",
    "# x = Conv2D(64, kernel_size=3, padding='same' ,activation='relu', kernel_initializer=initializer)(x)\n",
    "# x = AveragePooling2D(pool_size=(2, 2))(x)\n",
    "# x = Dropout(0.2)(x)\n",
    "\n",
    "x = Flatten()(x)\n",
    "x = Dense(32, activation='relu', kernel_initializer=initializer)(x)\n",
    "output = Dense(num_classes, activation='softmax')(x)\n",
    "model = Model(inputs=input1, outputs=output)\n",
    "\n",
    "## initiate RMSprop optimizer\n",
    "\n",
    "opt = keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=None, decay=1e-4)\n",
    "\n",
    "opt1 = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0, amsgrad=False)\n",
    "\n",
    "opt2 = keras.optimizers.SGD(lr=0.01, momentum=0.0, decay=0.0, nesterov=False)\n",
    "\n",
    "## Let's train the model using RMSprop\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', \n",
    "              \n",
    "              optimizer=opt, \n",
    "              \n",
    "              metrics=['accuracy'])\n",
    "## Scale 0-255 bands range into float 0-1\n",
    "x_train = x_train.astype('float32')\n",
    "\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "x_train /= 100\n",
    "\n",
    "x_test /= 100\n",
    "\n",
    "print(model.summary()) # summarize layers\n",
    "#plot_model(model, to_file='convolutional_neural_network.png') # plot graph of CNN structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cnn = model.fit(x_train, y_train,\n",
    "          \n",
    "              batch_size=batch_size,\n",
    "\n",
    "              epochs=epochs,\n",
    "\n",
    "              validation_data=(x_test, y_test),\n",
    "          \n",
    "              verbose=1,\n",
    "\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Training Stats ####\n",
    "\n",
    "plt.figure(5)\n",
    "\n",
    "plt.plot(cnn.history['acc'],'r')\n",
    "\n",
    "plt.plot(cnn.history['val_acc'],'g')\n",
    "\n",
    "plt.xticks(np.arange(0, epochs+1, 10))\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (8, 6)\n",
    "\n",
    "plt.xlabel(\"Num of Epochs\")\n",
    "\n",
    "plt.ylabel(\"Accuracy\")\n",
    "\n",
    "plt.title(\"Training Accuracy vs Validation Accuracy\")\n",
    "\n",
    "plt.legend(['train','validation'])\n",
    "\n",
    "\n",
    "plt.figure(6)\n",
    "\n",
    "plt.plot(cnn.history['loss'],'r')\n",
    "\n",
    "plt.plot(cnn.history['val_loss'],'g')\n",
    "\n",
    "plt.xticks(np.arange(0, epochs+1, 10))\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (8, 6)\n",
    "\n",
    "plt.xlabel(\"Num of Epochs\")\n",
    "\n",
    "plt.ylabel(\"Loss\")\n",
    "\n",
    "plt.title(\"Training Loss vs Validation Loss\")\n",
    "\n",
    "plt.legend(['train','validation'])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "#### Save model ####\n",
    "\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "\n",
    "model.save(model_path)\n",
    "\n",
    "print('Saved trained model at %s ' % model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Model testing ####\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "\n",
    "print('Test loss:', scores[0])\n",
    "\n",
    "print('Test accuracy:', scores[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
